<html lang="en">
<head>
  <meta charset="UTF-8">
  <title>SpectroGAN Demo Page</title>
  <!-- 합쳐지고 최소화된 최신 CSS -->
<link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.2/css/bootstrap.min.css">
<!-- 부가적인 테마 -->
<link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.2/css/bootstrap-theme.min.css">
<!-- 합쳐지고 최소화된 최신 자바스크립트 -->
<script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.2/js/bootstrap.min.js"></script>
  <style>
    .example {
    font-size:20px;
    padding-left:10px;
    }

    td{
        width:400px;
        text-align:center;
        white-space:nowrap;
        padding-left:15px;
    }
</style>
</head>

<body style='padding-left: 20px'>
  <h1 style="display:inline">Brain-to-Speech: Speech Synthesis from Non-invasive Brain Signals</h1>


  <br></br>
<h2>Abstract</h2>
  <p style="width:65%">Most non-invasive brain signals based brain-computer interface (BCI) communication studies primarily use stimulus-driven approaches (e.g., ERP or SSVEP spellers). 
Recently, the invasive brain signal (Electrocorticography) based speech synthesis firstly introduced technology that translates neural activity into speech from neural decoding of spoken sentences.
The fundamental objective of this paper is to investigate a sentence-level speech synthesis based on non-invasive brain signals (Electroencephalography, EEG) for the most intuitive BCI communication system.
Thus, our study presents a brain-to-speech (BTS) synthesis model, which can generate a speech from EEG signal of spoken sentences, namely, the BTS framework.
The proposed BTS framework consists of brain signal processing (i.e., recording, artifacts removal, etc.), frame-level linguistic conditional feed-forward Transformer networks to generate mel-spectrogram from EEG spectrogram, and vocoder to generate high-quality waveform from generated mel-spectrogram. From the encoder-attention-decoder based autoregressive teacher text-to-speech model, we extract attention alignments for frame-level target character mapping to predict the frame-level linguistic information.
Consequently, we successfully demonstrated the non-invasive based sentence-level BTS synthesis for the intuitive BCI communication system.
Thus our paper contributes to the deep question of how to solve the sentence-level speech synthesis from a non-invasive brain signal with large noise.
These results indicate that the use of the proposed BTS framework is more beneficial for brain-to-speech synthesis when developing intuitive BCI communication applications for severely paralyzed patients with neurological disorders or motor disabilities, such as amyotrophic lateral sclerosis or spinal cord injury.</p>
  <h2>Audio Samples</h2>
<p style="width:80%">oo</p>
  <h3>Speech naturalness</h3>	
  <br>
    <p style="width:65%">All of the generated sentences are not used during training</p>
  <p style="width:80%">1. <i>나는 바보입니다.</i></p>
  <table width="600">
  <thead>
  <tr>
  <th width="200" style="text-align: center">Raw Audio</th>
  <th width="200" style="text-align: center">Mel + MelGAN</th>
  <th width="200" style="text-align: center">Tacotron2</th>
  </tr>
  </thead>
  <tbody>
  <tr>
  <td style="text-align: center">
  <audio controls><source src="./demo_page/sample1/"></audio>		
  </td>
    <td style="text-align: center">
  <audio controls><source src="./demo_page/sample1/"></audio>		
  </td>
    <td style="text-align: center">
  <audio controls><source src="./demo_page/sample1/"></audio>		
  </td>
  </tr>
  </tbody>
  </table>
  <br>
  <table width="600">
  <thead>
  <tr>
  <th width="200" style="text-align: center">FastSpeech</th>
  <th width="200" style="text-align: center">BTS(with speech-related artifacts)</th>
  <th width="200" style="text-align: center">BTS(with artifacts removal</th>
  </tr>
  </thead>
  <tbody>
  <tr>
  <td style="text-align: center">
  <audio controls><source src="./demo_page/sample1/"></audio>		
  </td>
    <td style="text-align: center">
  <audio controls><source src="./demo_page/sample1/"></audio>		
  </td>
    <td style="text-align: center">
  <audio controls><source src="./demo_page/sample1/"></audio>		
  </td>
  </tr>
  </tbody>
  </table>
  <br>
<h2>Model</h2>
  <h3>brain-to-speech architecture</h3>
  <td><img src="./demo_page/figure2.png" width="1000"></td>
  <br>
  <h3>Architecture details</h3>
  <br>
<td><img src="./demo_page/figure3.png" width="700"></td>
	
</body>
</html>
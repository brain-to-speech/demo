<html lang="en">
<head>
  <meta charset="UTF-8">
  <title>Brain-to-Speech Demo Page</title>
  <!-- 합쳐지고 최소화된 최신 CSS -->
<link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.2/css/bootstrap.min.css">
<!-- 부가적인 테마 -->
<link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.2/css/bootstrap-theme.min.css">
<!-- 합쳐지고 최소화된 최신 자바스크립트 -->
<script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.2/js/bootstrap.min.js"></script>
  <style>
    .example {
    font-size:20px;
    padding-left:10px;
    }

    td{
        width:400px;
        text-align:center;
        white-space:nowrap;
        padding-left:15px;
    }
</style>
</head>

<body style='padding-left: 20px'>
  <h1 style="display:inline">Brain-to-Speech: Speech Synthesis from Non-invasive Brain Signals</h1>


  <br></br>
<h2>Abstract</h2>
  <p style="width:65%">Most communication studies on non-invasive brain signals using a brain–machine interface (BMI) have primarily applied a stimulus-driven approach (e.g., ERP or SSVEP spellers). 
An invasive brain signal (i.e., electrocorticography (ECoG)) based speech synthesis was the first technology introduced that translates neural activities into speech from a neural decoding of spoken sentences.
The fundamental objective of the present study is to investigate a sentence-level speech synthesis based on non-invasive brain signals, i.e., Electroencephalography (EEG), for the most intuitive BCI communication systems. 
Thus, our study presents a brain-to-speech (BTS) synthesis model that can generate speech from the EEG signals of spoken sentences, namely, a BTS framework.
The proposed BTS framework consists of brain signal processing (e.g., recording and artifact removal), frame-level linguistic-conditional feed-forward transformer networks to generate mel-spectrograms from EEG spectrograms, and a vocoder to generate a high-quality waveform from the neural network generated mel-spectrograms.
We extract attention alignments from an encoder-attention-decoder-based autoregressive teacher text-to-speech model for frame-level target character mapping to predict the frame-level linguistic information. 
In this manner, we successfully demonstrate a non-invasive based sentence-level BTS synthesis for an intuitive BCI communication system. 
Thus, our study contributes to the deep question of how to solve a sentence-level speech synthesis from a non-invasive brain signal with large noise. 
The results indicate that the use of the proposed BTS framework could ultimately be beneficial for a brain-to-speech synthesis when developing intuitive BCI communication applications for severely paralyzed patients with neurological disorders or motor disabilities, including those with amyotrophic lateral sclerosis or spinal cord injury.</p>
  <h2>Audio Samples</h2>
<p style="width:80%">oo</p>
  <h3>Speech naturalness</h3>	
  <br>
    <p style="width:65%">All of the generated sentences are not used during training</p>
  <p style="width:80%">1. <i>나는 바보입니다.</i></p>
  <table width="600">
  <thead>
  <tr>
  <th width="200" style="text-align: center">Raw Audio</th>
  <th width="200" style="text-align: center">Mel + MelGAN</th>
  <th width="200" style="text-align: center">Tacotron2</th>
  </tr>
  </thead>
  <tbody>
  <tr>
  <td style="text-align: center">
  <audio controls><source src="./demo_page/sample1/"></audio>		
  </td>
    <td style="text-align: center">
  <audio controls><source src="./demo_page/sample1/"></audio>		
  </td>
    <td style="text-align: center">
  <audio controls><source src="./demo_page/sample1/"></audio>		
  </td>
  </tr>
  </tbody>
  </table>
  <br>
  <table width="600">
  <thead>
  <tr>
  <th width="200" style="text-align: center">FastSpeech</th>
  <th width="200" style="text-align: center">BTS(with speech-related artifacts)</th>
  <th width="200" style="text-align: center">BTS(with artifacts removal</th>
  </tr>
  </thead>
  <tbody>
  <tr>
  <td style="text-align: center">
  <audio controls><source src="./demo_page/sample1/"></audio>		
  </td>
    <td style="text-align: center">
  <audio controls><source src="./demo_page/sample1/"></audio>		
  </td>
    <td style="text-align: center">
  <audio controls><source src="./demo_page/sample1/"></audio>		
  </td>
  </tr>
  </tbody>
  </table>
  <br>
<h2>Model</h2>
  <h3>brain-to-speech architecture</h3>
  <td><img src="./demo_page/figure2.png" width="1000"></td>
  <br>
  <h3>Architecture details</h3>
  <br>

	
</body>
</html>